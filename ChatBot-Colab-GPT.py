# -*- coding: utf-8 -*-
"""LLM-Chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZxkF_oOLJm0FqrJMHB-_XvYI09M1YARm

Install the required dependencies
"""

!pip install -U langchain-community

!pip install openai tiktoken
!pip install -q cassio
!pip install -q datasets
!pip install -q langchain

"""Import the packages we'll need:"""

# Importerer Cassandra-klassen fra LangChain biblioteket, som brukes for å lagre vektorer i en Cassandra database
from langchain.vectorstores.cassandra import Cassandra

# Importerer VectorStoreIndexWrapper for å håndtere indeksering av vektorer lagret i Cassandra
from langchain.indexes.vectorstore import VectorStoreIndexWrapper

# Importerer OpenAI klassen fra LangChain biblioteket, som brukes til å interagere med OpenAI's språkmodeller
from langchain.llms import OpenAI

# Importerer OpenAIEmbeddings for å generere vektorrepresentasjoner (embeddings) ved hjelp av OpenAI's modeller
from langchain.embeddings import OpenAIEmbeddings

# Importerer load_dataset funksjonen fra Hugging Face biblioteket, som brukes for å laste inn forhåndsdefinerte datasett
from datasets import load_dataset

# Importerer cassio modulen som brukes for å initialisere og håndtere forbindelsen til Astra DB via CassIO motoren
import cassio

!pip install PyPDF2

"""Get astra Token&ID from https://accounts.datastax.com/session-service/v1/login and API key from https://platform.openai.com/api-keys"""

ASTRA_DB_APPLICATION_TOKEN = "AstraCS:pHthlPvEItqAxGXyuNEpqjCG:50ca779af9a4ddc9de0c8f3714c148cd7e114f3542c5a3226fb2e0b28cea7f80"
ASTRA_DB_ID = "45a6632a-6cfb-4b6b-870f-6ae3fe305573"
OPENAI_API_KEY = ""

from google.colab import files
from PyPDF2 import PdfReader

# Initialize raw_text to store content from all files
raw_text = ''

while True:
    # Upload the PDF files
    uploaded_files = files.upload()

    # List of uploaded file names
    filenames = list(uploaded_files.keys())

    if len(filenames) == 0:
        print("No files selected. Exiting file selection loop.")
        break

    # Loop through each uploaded file
    for filename in filenames:
        with open(filename, 'rb') as f:
            pdf_reader = PdfReader(f)
            # Loop through each page in the PDF file
            for page in pdf_reader.pages:
                # Extract text from each page
                content = page.extract_text()
                # Add the extracted text to the raw text variable
                if content:
                    raw_text += content

print("File processing complete.")

raw_text

"""Initialize the connection to our database:"""

cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)

"""Create the LangChain embedding and LLM objects for later usage:"""
llm = OpenAI(openai_api_key=OPENAI_API_KEY)
embedding = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)

"""Create our LangChain vector store ... backed by Astra DB!"""

# Initialiserer en Cassandra vektorlager for å lagre og hente embeddings.
# Bruker det opprettede embedding-objektet fra OpenAI, og spesifiserer navnet på tabellen som skal brukes.
# Session og keyspace er ikke spesifisert her, men kan legges til om nødvendig for å tilpasse tilkoblingen.
astra_vector_store = Cassandra(
    embedding=embedding,
    table_name="qa_mini_demo",
    session=None,
    keyspace=None,
)

from langchain.text_splitter import CharacterTextSplitter

text_splitter = CharacterTextSplitter(

    separator="\n",
    # Maksimal størrelse på hver tekstdel i antall tegn.
    chunk_size=850,
    # Antall tegn som kan overlappe mellom påfølgende tekstdeler, for å sikre sammenheng mellom deler.
    chunk_overlap=250,
    # Funksjonen som brukes for å beregne lengden av teksten. Her brukes len-funksjonen som teller antall tegn.
    length_function=len,
)

# Deler den rå teksten (raw_text) i mindre deler ved å bruke den definerte text_splitteren.
texts = text_splitter.split_text(raw_text)

texts[:300]

"""### Load the dataset into the vector store"""

astra_vector_store.add_texts(texts[:100])

print("Inserted %i headlines." % len(texts[:400]))

# Initialiserer en VectorStoreIndexWrapper for å håndtere indeksering og effektivt søk i vektorlagrede data.
# Bruker det opprettede Cassandra vektorlageret som backend for indekseringen.
astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)

first_question = True
while True:
    if first_question:
        query_text = input("\nEnter your question (or type 'quit' to exit): ").strip()
    else:
        query_text = input("\nWhat's your next question (or type 'quit' to exit): ").strip()

    if query_text.lower() == "quit":
        break

    if query_text == "":
        continue

    first_question = False

    print("\nQUESTION: \"%s\"" % query_text)
    answer = astra_vector_index.query(query_text, llm=llm).strip()
    print("ANSWER: \"%s\"\n" % answer)

"""####Gradio interface
:
"""

!pip install -q gradio
import gradio as gr

"""Bruker grensesnitt step1.

"""

import gradio as gr

# Definerer funksjonen som skal kjøre modellen
def run_model(query_text):
    if query_text.lower() == "quit":
        return "Goodbye!"
    elif query_text == "":
        return "Please enter a question."

    return astra_vector_index.query(query_text, llm=llm).strip()

# Sett opp gradio-grensesnittet
inputs = gr.Textbox(label="Enter your question (or type 'quit' to exit)")
output = gr.Textbox()

# Koble modellen til gradio-grensesnittet
gr.Interface(fn=run_model, inputs=inputs, outputs=output, title="Question Answering System").launch()

import os
import time
pdf_files = [
    'Andre permisjoner.pdf', 'Arbeidstid.pdf', 'Ferie.pdf', 'Feriepenger.pdf', 'Fjernledelse.pdf',
    'Foreldrepermisjon.pdf', 'Forsikring.pdf', 'HMS.pdf', 'Honorar.pdf', 'Inkluderende arbeidsliv.pdf',
    'Kompetanse _ e-læring.pdf', 'Lønnsendring.pdf', 'Medarbeider- og utviklingssamtalen.pdf',
    'Mobbing og trakassering.pdf', 'Månedslønn.pdf', 'Nyansatt.pdf', 'Omsorgspermisjon.pdf',
    'Oppsigelse.pdf', 'Overtid.pdf', 'Pensjon.pdf', 'Planlegge og gjennomføre reise.pdf',
    'Registrering av reise i SAP-portalen.pdf', 'Skattetrekk.pdf', 'Stedfortredergodtgjørelse.pdf',
    'Sykdom.pdf', 'Tillitsverv.pdf', 'Timelønn.pdf', 'Utlegg.pdf', 'Varsling av kritikkverdige forhold.pdf',
    'Lønnsslipp med forklaring.pdf','Hei'
]


def get_file_name(question):
    """Determine the file name from the question based on keyword matching."""
    for file_name in pdf_files:
        for keyword in question.split():
            if keyword.lower() in file_name.lower():
                return file_name
    return "File not found"


def answer_question(question):
    """Generate answers to questions using a vector search index and link to documents or contact information."""
    if question.lower() == "quit":
        return "Quitting..."
    if question == "":
        return "skriv Ditt spørsmål."

    answer = astra_vector_index.query(question, llm=llm).strip()
    file_name = get_file_name(question)

    if file_name != "File not found":
        url_safe_file_name = file_name.replace(' ', '-').replace('.pdf', '').lower()
        url = f"https://husnettet-d/HR-Portalen/For-ansatte/Sider/{url_safe_file_name}"
        return f"{answer} Les mer her: <a href='{url}' target='_blank' style='color: blue;'>{url_safe_file_name}</a>"
    else:
        email = "hr-service@husbanken.no"
        return f"{answer} Hvis du trenger mer spesifikk informasjon, vennligst kontakt HR-service på: <a href='mailto:{email}' style='color: blue;'>Hr_service</a>."

def respond(message, chat_history):
    """Process messages, append to chat history, and simulate response delay."""
    answer_html = answer_question(message)
    chat_history.append((message, answer_html))
    time.sleep(2)
    return "", chat_history

def vote(data: gr.LikeData):
    if data.liked:
        print("You upvoted this response: " + data.value)
    else:
        print("You downvoted this response: " + data.value)

css = """
body, .gradio-container {
    background-color: #C1DAAE;
    color: #485865;
}
.gradio-container .gr-powered-by, .gradio-container .gr-use-via-api {
    color: black !important;
}
"""

js = """
function createGradioAnimation() {
    var container = document.createElement('div');
    container.id = 'gradio-animation';
    container.style.fontSize = '2em';
    container.style.fontWeight = 'bold';
    container.style.textAlign = 'center';
    container.style.marginBottom = '10px';
    var text = 'Velkommen til Chatbot';
    var gradioContainer = document.querySelector('.gradio-container');
    gradioContainer.insertBefore(container, gradioContainer.firstChild);
    text.split('').forEach((char, i) => {
        setTimeout(() => {
            var letter = document.createElement('span');
            letter.style.opacity = '0';
            letter.style.transition = 'opacity 0.5s';
            letter.innerText = char;
            container.appendChild(letter);
            setTimeout(() => letter.style.opacity = '1', 25);
        }, i * 200);
    });
    return 'Animation created';
}
"""

if __name__ == "__main__":
    with gr.Blocks(theme=gr.themes.Default(primary_hue="green", secondary_hue="green"), js=js, css=css) as demo:
        chatbot = gr.Chatbot()
        msg = gr.Textbox(label="Ditt spørsmål:")
        clear = gr.ClearButton([msg, chatbot])
        chatbot.like(vote, None, None)  # Adding this line causes the like/dislike icons to appear in chatbot
        msg.submit(respond, inputs=[msg, chatbot], outputs=[msg, chatbot])
        #demo.launch()
        demo.launch(auth = ('userNam', '123*'), auth_message= "Skriv inn brukernavn og passord")